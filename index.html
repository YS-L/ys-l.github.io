<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!--<meta name="description" content="A layout example that shows off a blog page with a list of posts."> -->
    <title>Recent Posts</title>
    <link rel="stylesheet" href="//cdn.jsdelivr.net/g/pure@0.6.0(pure-min.css+grids-responsive-min.css)">
    <!--
    <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.5.0/pure-min.css">
    -->
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.5.0/grids-responsive-old-ie-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <!--
        <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.5.0/grids-responsive-min.css">
        -->
    <!--<![endif]-->

    <!--[if lte IE 8]>
        <link rel="stylesheet" href="css/layouts/blog-old-ie.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="./css/blog.css">
    <!--<![endif]-->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="./css/syntax.css">
    <script>
      if (document.location.hostname.search("ys-l.github.io") !== -1) {
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-67247266-1', 'auto');
        ga('send', 'pageview');
      }
    </script>
  </head>

  <body>
    <div id="layout" class="pure-g">

      <div class="sidebar pure-u-1">
        <div class="header">
          <h1 class="brand-title">Liau Yung Siang</h1>
          <h2 class="brand-tagline">code, data, machine learning, ai</h2>
          <nav class="nav">
            <ul class="nav-list">
              <li class="nav-item">
                <a class="pure-button" href="./">Home</a>
              </li>
              <li class="nav-item">
                <a class="pure-button" href="./archive">Archive</a>
              </li>
              <li class="nav-item">
                <a class="pure-button" href="./about">About</a>
              </li>
            </ul>
            <div class="icon-links">
              <a href="http://twitter.com/ysliau"><i class="fa fa-twitter fa-2x"></i></a>
              <a href="http://github.com/YS-L"><i class="fa fa-github fa-2x"></i></a>
            </div>
          </nav>
        </div>
      </div>

      <div class="pure-u-1">
          <div class="content">
          <p class="page-title">Recent Posts</p>
          <div class="post-description">
            <style>
  .home-padding {
    margin-bottom: 1cm;
  }
</style>
<p class="home-padding">
</p>

  <div class="post-list-snippet">
    <a href="./posts/2016/01/15/removing-the-close-button-on-chromiums-tab/" class="post-title">Removing the Close Button on Chromium's tab</a>
    <span class="post-list-meta">January 15, 2016</span>
    <p class="post-description">
    <!--
    
    -->
    <p>I have the <em>fat mouse syndrome</em> – there have been numerous times when I accidentally closed a tab when I actually meant to switch to that tab. I tend to keep many tabs open, which probably made the problem worse. It looks something like this:</p>
<p><img src="./images/remove-close-buttons-before.png" style="width: 100%" /></p>
<p>While Chromium automatically hides the close button when the length of the tabs becomes very small, it does not help much since fat mouse errors can occur way before that. Also, to close a tab, I normally use the middle mouse button or the keyboard shortcut <code>Ctrl-W</code>, yielding a complete negative utility for these close buttons. Apparently, I’m <a href="https://productforums.google.com/forum/#!topic/chrome/lke8SOdV5y0">not</a> <a href="http://stackoverflow.com/questions/11889044/any-way-to-remove-x-button-from-chrome-tabs">the</a> <a href="http://superuser.com/questions/199384/how-to-disable-the-close-x-button-on-google-chrome-tabs">only</a> <a href="https://www.reddit.com/r/chrome/comments/351vzd/is_there_a_way_to_remove_close_tab_x_button/">one</a> who got annoyed.</p>
<h2 id="patching-chromium">Patching Chromium</h2>
<p>Unfortunately, this aspect of UI isn’t user configurable. To get rid of these close buttons, some hacking on Chromium’s source code is required. I did that. It’s actually a little simpler than I had imagined thanks to the excellent code search engine and very high quality source code. After some digging, it turns out there is a well isolated function that decides whether the close button should be shown for each tab. To always hide the close button, simply short-circuit this function.</p>
<p>As mentioned, the patch is quite simple:</p>
<div class="sourceCode"><pre class="sourceCode diff"><code class="sourceCode diff">From f6283382f6f92581bd52202f400841753c5418e0 Mon Sep 17 00:00:00 2001
From: Yung Siang Liau &lt;liauys@gmail.com&gt;
Date: Sun, 1 Nov 2015 14:18:20 +0800
Subject: [PATCH] Always hide close button

<span class="kw">---</span>
 chrome/browser/ui/tabs/tab_utils.cc | 3 +++
 1 file changed, 3 insertions(+)

<span class="kw">diff --git a/chrome/browser/ui/tabs/tab_utils.cc b/chrome/browser/ui/tabs/tab_utils.cc</span>
index cd088c4..3129461 100644
<span class="kw">--- a/chrome/browser/ui/tabs/tab_utils.cc</span>
<span class="dt">+++ b/chrome/browser/ui/tabs/tab_utils.cc</span>
<span class="dt">@@ -132,12 +132,15 @@ bool ShouldTabShowMediaIndicator(int capacity,</span>
 bool ShouldTabShowCloseButton(int capacity,
                               bool is_pinned_tab,
                               bool is_active_tab) {
<span class="ot">+  return false;</span>
<span class="ot">+  /*</span>
   if (is_pinned_tab)
     return false;
   else if (is_active_tab)
     return true;
   else
     return capacity &gt;= 3;
<span class="ot">+  */</span>
 }
 
 TabMediaState GetTabMediaStateForContents(content::WebContents* contents) {
<span class="st">-- </span>
<span class="dt">2.6.3</span></code></pre></div>
<p>Result (after two hours of compilation):</p>
<p><img src="./images/remove-close-buttons-after.png" style="width: 100%" /></p>
<p>Yes!</p>
<h2 id="packaging-for-archlinux">Packaging (for ArchLinux)</h2>
<p>I made an ArchLinux package description (PKGBUILD) for the above patched chromium based on the chromium package on ArchLinux official repository. It can be found <a href="https://github.com/YS-L/chromium-minimal-tab">here</a>.</p>
    </p>
  </div>
  <div class="post-separator">
    <i class="fa fa-gg"></i>
  </div>

  <div class="post-list-snippet">
    <a href="./posts/2015/10/03/processifying-bulky-functions-in-python/" class="post-title">Processifying Bulky Functions in Python</a>
    <span class="post-list-meta">October  3, 2015</span>
    <p class="post-description">
    <!--
    
        <p>Long running Python scripts that repeatedly call “bulky” functions can incur growing memory usage over time. Other than calling <code>gc.collect()</code> and pray hard, can we do a bit better in dealing with the heavy memory footprint? 
        <p align="right"><a href="/posts/2015/10/03/processifying-bulky-functions-in-python/index.html" class="read-more-link"> Read more <i class="fa fa-chevron-right"></i></a><p>
    
    -->
    <p>Long running Python scripts that repeatedly call “bulky” functions can incur growing memory usage over time. Other than calling <code>gc.collect()</code> and pray hard, can we do a bit better in dealing with the heavy memory footprint? <!--more--></p>
<h2 id="the-problem-with-bulky-functions">The problem with bulky functions</h2>
<p>Some real examples I had faced include scripts that evaluate performance of many different combinations of features and model on a dataset:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> evaluate(features, model):
    <span class="co"># Load some big features</span>
    <span class="co"># Train a big model</span>
    <span class="co"># Measure the performance</span>
    <span class="co"># After all the bulky work, return a number or a small dict, etc.</span>
    <span class="cf">return</span> score</code></pre></div>
<p>In a single Python script, repeatedly calling the above bulky function can cause the memory usage to grow over time, even though the calls are really independent of each other. That is to say, some amount of lingering memory will accumulate after every call to the function, as if there is an on-going memory leak. This continues until one has to restart the script to trigger a “refresh” to free up the memory.</p>
<h2 id="possible-solutions">Possible solutions</h2>
<h4 id="find-out-where-the-memory-leak-is-with-a-profiler">0. Find out where the memory leak is with a profiler</h4>
<p>This is probably the only real solution to the problem. However, the effort needed might be too much for exploratory code that will not go into production. Sometimes, something more pragmatic is needed.</p>
<h4 id="gc.collect">1. <code>gc.collect()</code></h4>
<p>This attempts to force the garbage collector to do its work. Often preceded by some <code>del ...</code> statements. Unfortunately, there is no guarantee that the memory will be released.</p>
<h4 id="invoke-each-execution-of-evaluate-in-a-new-process-e.g.with-a-driver-shell-script">2. Invoke each execution of <code>evaluate()</code> in a new process, e.g. with a “driver” shell script</h4>
<p>Now we are getting somewhere. The OS will be forced to clean up the memory incurred by the function, when the process terminates. However, this requires a lot of extra boilerplate code to be written – a command line interface and a shell script. Besides the annoying context switching of the mind between languages, more importantly this approach is only feasible for simple “end-user” function such as the one shown in this example. Generally, for a bulky function that needs to be called periodically within another function, we need to stay within the Python interpreter.</p>
<h4 id="spawn-a-new-process-in-python-that-will-execute-the-function">3. Spawn a new process in Python that will execute the function</h4>
<p>Indeed, we can spawn a new process to execute the function using the <code>multiprocessing</code> module. This requires modification to the <code>evaluate()</code> function so that it takes in a <code>Queue</code> object for communicating back the result. Perhaps more preferably, we can make use of the <code>Pool</code> interface to help with the result communication:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> multiprocessing <span class="im">import</span> Pool
pool <span class="op">=</span> Pool(processes<span class="op">=</span><span class="dv">1</span>)
result <span class="op">=</span> pool.<span class="bu">apply</span>(evaluate, features, model)</code></pre></div>
<p>Looks acceptable. However, what if an exception is raised somewhere in the function? The error traceback now becomes</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="op">/</span>usr<span class="op">/</span>lib64<span class="op">/</span>python2<span class="fl">.7</span><span class="op">/</span>multiprocessing<span class="op">/</span>pool.pyc <span class="op">in</span> <span class="bu">apply</span>(<span class="va">self</span>, func, args, kwds)
    <span class="dv">242</span>         <span class="st">'''</span>
<span class="st">    243         assert self._state == RUN</span>
<span class="st">--&gt; 244         return self.apply_async(func, args, kwds).get()</span>
<span class="st">    245</span>
<span class="st">    246     def map(self, func, iterable, chunksize=None):</span>

<span class="st">/usr/lib64/python2.7/multiprocessing/pool.pyc in get(self, timeout)</span>
<span class="st">    565             return self._value</span>
<span class="st">    566         else:</span>
<span class="st">--&gt; 567             raise self._value</span>
<span class="st">    568</span>
<span class="st">    569     def _set(self, i, obj):</span>

<span class="st">ValueError: operands could not be broadcast together with shapes (10,2) (10,20)</span></code></pre></div>
<p>regardless of where the exception is actually raised. As one can guess, staring at the source code of the multiprocessing module is not particularly informative for debugging an error in the user level code<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. Some further hacking is necessary to float the actual context up to the user on exception. Also, having to interact with the <code>Pool</code> object every time is kind of distracting. In other words, this solution is close but not yet ideal.</p>
<h2 id="the-processify-decorator">The <code>processify</code> decorator</h2>
<p>Recently, I found a neat piece of code in the wild that solves this problem – the <code>processify</code> decorator. Full credit goes to <a href="https://gist.github.com/schlamar/2311116">schlamar</a> who posted it on GitHub Gist. For completeness, I will show the (slightly modified) code here:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> os
<span class="im">import</span> sys
<span class="im">import</span> traceback
<span class="im">from</span> functools <span class="im">import</span> wraps
<span class="im">from</span> multiprocessing <span class="im">import</span> Process, Queue


<span class="kw">def</span> processify(func):
    <span class="co">'''Decorator to run a function as a process.</span>
<span class="co">    Be sure that every argument and the return value</span>
<span class="co">    is *pickable*.</span>
<span class="co">    The created process is joined, so the code does not</span>
<span class="co">    run in parallel.</span>
<span class="co">    '''</span>

    <span class="kw">def</span> process_func(q, <span class="op">*</span>args, <span class="op">**</span>kwargs):
        <span class="cf">try</span>:
            ret <span class="op">=</span> func(<span class="op">*</span>args, <span class="op">**</span>kwargs)
        <span class="cf">except</span> <span class="pp">Exception</span>:
            ex_type, ex_value, tb <span class="op">=</span> sys.exc_info()
            error <span class="op">=</span> ex_type, ex_value, <span class="st">''</span>.join(traceback.format_tb(tb))
            ret <span class="op">=</span> <span class="va">None</span>
        <span class="cf">else</span>:
            error <span class="op">=</span> <span class="va">None</span>

        q.put((ret, error))

    <span class="co"># register original function with different name</span>
    <span class="co"># in sys.modules so it is pickable</span>
    process_func.<span class="va">__name__</span> <span class="op">=</span> func.<span class="va">__name__</span> <span class="op">+</span> <span class="st">'processify_func'</span>
    <span class="bu">setattr</span>(sys.modules[<span class="va">__name__</span>], process_func.<span class="va">__name__</span>, process_func)

    <span class="at">@wraps</span>(func)
    <span class="kw">def</span> wrapper(<span class="op">*</span>args, <span class="op">**</span>kwargs):
        q <span class="op">=</span> Queue()
        p <span class="op">=</span> Process(target<span class="op">=</span>process_func, args<span class="op">=</span>[q] <span class="op">+</span> <span class="bu">list</span>(args), kwargs<span class="op">=</span>kwargs)
        p.start()
        ret, error <span class="op">=</span> q.get()

        <span class="cf">if</span> error:
            ex_type, ex_value, tb_str <span class="op">=</span> error
            message <span class="op">=</span> <span class="st">'</span><span class="sc">%s</span><span class="st"> (in subprocess)</span><span class="ch">\n</span><span class="sc">%s</span><span class="st">'</span> <span class="op">%</span> (ex_value.message, tb_str)
            <span class="cf">raise</span> ex_type(message)

        <span class="cf">return</span> ret
    <span class="cf">return</span> wrapper</code></pre></div>
<p>Note: In the original version, the usage of <code>p.join()</code> causes a risk of deadlock situation if the object returned from the target function is too large. The above code has been modified and it seems to have solved the problem. More information can be found in the comment section of the <a href="https://gist.github.com/schlamar/2311116">Gist</a>.</p>
<p>To use it, simply decorate the bulky function:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="at">@processify</span>
<span class="kw">def</span> evaluate(features, model):
    <span class="co"># Load some big features</span>
    <span class="co"># Train a big model</span>
    <span class="co"># Measure the performance</span>
    <span class="co"># After all the bulky work, return a number or a small dict, etc.</span>
    <span class="cf">return</span> score</code></pre></div>
<p>and the function will be run cleanly in a new process, as long as the input and output of the function are picklable.</p>
<p>Very nice! What I like about it is:</p>
<ol style="list-style-type: decimal">
<li>Very easy to use, no modification to the original function required (in fact, this is probably a perfect use case of a decorator)</li>
<li>A trick that seems to successfully pickle nested function</li>
<li>Able to show some useful context on exception as opposed to the case above using <code>Pool</code>.</li>
</ol>
<p>Regarding point (3) above, consider the following code:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="at">@processify</span>
<span class="kw">def</span> work():
    <span class="co">&quot;&quot;&quot;Get things done here&quot;&quot;&quot;</span>
    <span class="im">import</span> numpy <span class="im">as</span> np
    np.random.rand(<span class="dv">10</span>,<span class="dv">2</span>) <span class="op">+</span> np.random.rand(<span class="dv">10</span>,<span class="dv">20</span>)
    <span class="cf">return</span> np.random.rand(<span class="dv">10</span>,<span class="dv">2</span>)

<span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:
    work()</code></pre></div>
<p>The error traceback is shown as:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="op">---------------------------------------------------------------------------</span>
<span class="pp">ValueError</span>                                Traceback (most recent call last)
<span class="op">&lt;</span>ipython<span class="op">-</span><span class="bu">input</span><span class="dv">-3</span><span class="op">-</span>c2d43235dcae<span class="op">&gt;</span> <span class="op">in</span> <span class="op">&lt;</span>module<span class="op">&gt;</span>()
     <span class="dv">66</span>
     <span class="dv">67</span> <span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:
<span class="op">---&gt;</span> <span class="dv">68</span>     work()

<span class="op">&lt;</span>ipython<span class="op">-</span><span class="bu">input</span><span class="dv">-3</span><span class="op">-</span>c2d43235dcae<span class="op">&gt;</span> <span class="op">in</span> wrapper(<span class="op">*</span>args, <span class="op">**</span>kwargs)
     <span class="dv">43</span>             ex_type, ex_value, tb_str <span class="op">=</span> error
     <span class="dv">44</span>             message <span class="op">=</span> <span class="st">'</span><span class="sc">%s</span><span class="st"> (in subprocess)</span><span class="ch">\n</span><span class="sc">%s</span><span class="st">'</span> <span class="op">%</span> (ex_value.message, tb_str)
<span class="op">---&gt;</span> <span class="dv">45</span>             <span class="cf">raise</span> ex_type(message)
     <span class="dv">46</span>
     <span class="dv">47</span>         <span class="cf">return</span> ret

<span class="pp">ValueError</span>: operands could <span class="op">not</span> be broadcast together <span class="cf">with</span> shapes (<span class="dv">10</span>,<span class="dv">2</span>) (<span class="dv">10</span>,<span class="dv">20</span>)  (<span class="op">in</span> subprocess)
  File <span class="st">&quot;&lt;ipython-input-3-c2d43235dcae&gt;&quot;</span>, line <span class="dv">18</span>, <span class="op">in</span> process_func
    ret <span class="op">=</span> func(<span class="op">*</span>args, <span class="op">**</span>kwargs)
  File <span class="st">&quot;&lt;ipython-input-3-c2d43235dcae&gt;&quot;</span>, line <span class="dv">55</span>, <span class="op">in</span> work
    np.random.rand(<span class="dv">10</span>,<span class="dv">2</span>) <span class="op">+</span> np.random.rand(<span class="dv">10</span>,<span class="dv">20</span>)</code></pre></div>
<p>which is quite helpful.</p>
<p>As long as a bulky function is repeatedly called in a coarse-grained manner (i.e. time spent in a single execution of function is dominant in the caller’s loop) and has lightweight input and output, the processifying trick is a sensible technique that can be used to control the memory usage.</p>
<p>I’ve added this to my standard utility toolbox for quick data analytics projects, and it just saved me a time or two in a recent competition which I’ll probably write about soon.</p>
<p>No more <code>gc.collect()</code> blindly!</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>This issue seems to have been fixed in Python 3.4: see the <a href="http://bugs.python.org/issue13831Ups">bug tracker</a><a href="#fnref1">↩</a></p></li>
</ol>
</div>
    </p>
  </div>
  <div class="post-separator">
    <i class="fa fa-gg"></i>
  </div>

  <div class="post-list-snippet">
    <a href="./posts/2015/08/28/how-not-to-use-pandas-apply/" class="post-title">How Not to Use pandas' "apply"</a>
    <span class="post-list-meta">August 28, 2015</span>
    <p class="post-description">
    <!--
    
        <p>Recently, I tripped over a use of the <code>apply</code> function in pandas in perhaps one of the worst possible ways. The scenario is this: we have a DataFrame of a moderate size, say 1 million rows and a dozen columns. We want to perform some row-wise computation on the DataFrame and based on which generate a few new columns. 
        <p align="right"><a href="/posts/2015/08/28/how-not-to-use-pandas-apply/index.html" class="read-more-link"> Read more <i class="fa fa-chevron-right"></i></a><p>
    
    -->
    <p>Recently, I tripped over a use of the <code>apply</code> function in pandas in perhaps one of the worst possible ways. The scenario is this: we have a DataFrame of a moderate size, say 1 million rows and a dozen columns. We want to perform some row-wise computation on the DataFrame and based on which generate a few new columns. <!--more--></p>
<p>Let’s also assume that the computation is rather complex, so those wonderful vectorized operations in that comes with pandas are out of question (the official <a href="http://pandas.pydata.org/pandas-docs/stable/enhancingperf.html">performance enhancement tips</a> is a nice read on this). And luckily it has been packaged as a function that returns a few values:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> complex_computation(a):
    <span class="co"># do lots of work here...</span>
    <span class="co"># ...</span>
    <span class="co"># and finally it's done.</span>
    <span class="cf">return</span> value1, value2, value3</code></pre></div>
<p>We want to put the computed results together into a new DataFrame.</p>
<p>A natural solution is to call the <code>apply</code> function of the DataFrame and pass in a function which does the said computation:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> func(row):
    v1, v2, v3 <span class="op">=</span> complex_computation(row[[<span class="st">'some'</span>, <span class="st">'columns'</span>]].values)
    <span class="cf">return</span> pd.Series({<span class="st">'NewColumn1'</span>: v1,
                      <span class="st">'NewColumn2'</span>: v2,
                      <span class="co">'NewColumn3'</span>: v3})
df_result <span class="op">=</span> df.<span class="bu">apply</span>(func, axis<span class="op">=</span><span class="dv">1</span>)</code></pre></div>
<p>According to the <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html">documentation</a> of <code>apply</code>, the result depends on what <code>func</code> returns. If we pass in such a <code>func</code> (returning a Series instead of a single value), the result would be a nice DataFrame containing three columns as named.</p>
<p>Expressed in a more loopy manner, the following yields an equivalent result:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">v1s, v2s, v3s <span class="op">=</span> [], [], []
<span class="cf">for</span> _, row <span class="op">in</span> df.iterrows():
    v1, v2, v3 <span class="op">=</span> complex_computation(row[[<span class="st">'some'</span>, <span class="st">'columns'</span>]].values)
    v1s.append(v1)
    v2s.append(v2)
    v3s.append(v3)
df_result <span class="op">=</span> pd.DataFrame({<span class="st">'NewColumn1'</span>: v1s,
                          <span class="st">'NewColumn2'</span>: v2s,
                          <span class="co">'NewColumn3'</span>: v3s})</code></pre></div>
<p>However, at the first glance, the loopy version just does not seem elegant compared to the <code>apply</code> version. Plus, leaving the work of putting together the results to pandas seems to be a good idea – could some magics be performed in the background by pandas, making the loop complete faster?</p>
<p>That was what I thought, but it turns out we have just constructed a silent memory eating monster with such use of <code>apply</code>. To see that, let’s put together the above pieces of code and consider a minimal reproducible example (and the pandas version here is <code>0.16.2</code>):</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="op">%</span>load_ext memory_profiler

<span class="kw">def</span> complex_computation(a):
    <span class="co"># Okay, this is not really complex, but this is just for illustration.</span>
    <span class="co"># To keep reproducibility, we can't make it order a pizza here.</span>
    <span class="co"># Anyway, pretend that there is no way to vectorize this operation.</span>
    <span class="cf">return</span> a[<span class="dv">0</span>]<span class="op">-</span>a[<span class="dv">1</span>], a[<span class="dv">0</span>]<span class="op">+</span>a[<span class="dv">1</span>], a[<span class="dv">0</span>]<span class="op">*</span>a[<span class="dv">1</span>]

<span class="kw">def</span> func(row):
    v1, v2, v3 <span class="op">=</span> complex_computation(row.values)
    <span class="cf">return</span> pd.Series({<span class="st">'NewColumn1'</span>: v1,
                      <span class="st">'NewColumn2'</span>: v2,
                      <span class="co">'NewColumn3'</span>: v3})

<span class="kw">def</span> run_apply(df):
    df_result <span class="op">=</span> df.<span class="bu">apply</span>(func, axis<span class="op">=</span><span class="dv">1</span>)
    <span class="cf">return</span> df_result

<span class="kw">def</span> run_loopy(df):
    v1s, v2s, v3s <span class="op">=</span> [], [], []
    <span class="cf">for</span> _, row <span class="op">in</span> df.iterrows():
        v1, v2, v3 <span class="op">=</span> complex_computation(row.values)
        v1s.append(v1)
        v2s.append(v2)
        v3s.append(v3)
    df_result <span class="op">=</span> pd.DataFrame({<span class="st">'NewColumn1'</span>: v1s,
                              <span class="st">'NewColumn2'</span>: v2s,
                              <span class="co">'NewColumn3'</span>: v3s})
    <span class="cf">return</span> df_result

<span class="kw">def</span> make_dataset(N):
    np.random.seed(<span class="dv">0</span>)
    df <span class="op">=</span> pd.DataFrame({
            <span class="st">'a'</span>: np.random.randint(<span class="dv">0</span>, <span class="dv">100</span>, N),
            <span class="st">'b'</span>: np.random.randint(<span class="dv">0</span>, <span class="dv">100</span>, N)
         })
    <span class="cf">return</span> df

<span class="kw">def</span> test():
    <span class="im">from</span> pandas.util.testing <span class="im">import</span> assert_frame_equal
    df <span class="op">=</span> make_dataset(<span class="dv">100</span>)
    df_res1 <span class="op">=</span> run_loopy(df)
    df_res2 <span class="op">=</span> run_apply(df)
    assert_frame_equal(df_res1, df_res2)
    <span class="bu">print</span> <span class="st">'OK'</span>

df <span class="op">=</span> make_dataset(<span class="dv">1000000</span>)  </code></pre></div>
<p>Before anything else, let’s check the correctness first on a small set of input data (i.e. both implementations yield identical results):</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">test()
<span class="co"># OK</span></code></pre></div>
<p>And now it’s time for some <code>%memit</code>. The loopy version gives:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="op">%</span>memit run_loopy(df)
<span class="co"># peak memory: 272.18 MiB, increment: 181.38 MiB</span></code></pre></div>
<p>How about the elegant <code>apply</code>?</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="op">%</span>memit run_apply(df)
<span class="co"># peak memory: 3941.29 MiB, increment: 3850.10 MiB</span></code></pre></div>
<p>Oops, that’s a 10 times more in memory usage! Not good. Apparently, in order to achieve its flexibility, the <code>apply</code> function somehow has to store all the intermediate <code>Series</code> that appeared along the way, or something like that.</p>
<p>Speed-wise we have:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="op">%</span>timeit run_loopy(df)
<span class="co"># 1 loops, best of 3: 36.2 s per loop</span>

<span class="op">%</span>timeit run_apply(df)
<span class="co"># 1 loops, best of 3: 2min 48s per loop</span></code></pre></div>
<p>Looping is slow; but it is actually a lot faster than this way of using <code>apply</code>! The overhead of creating a Series for every input row is just too much.</p>
<p>Combining both its memory and time inefficiency, I have just presented to you one of the worst possible ways to use the <code>apply</code> function in pandas. For some reason, this did not appear obvious to me when I first encountered it.</p>
<p><strong>TL;DR</strong>: When applying a function on a DataFrame using <code>DataFrame.apply</code> by row, be careful of what the function returns – making it return a <code>Series</code> so that <code>apply</code> results in a DataFrame can be very memory inefficient on input with many rows. And it is slow. Very slow.</p>
    </p>
  </div>
  <div class="post-separator">
    <i class="fa fa-gg"></i>
  </div>



          </div>
          <div class="footer">
            <span class="pure-text">Powered by</span> <a href="http://jaspervdj.be/hakyll">Hakyll</a>
          </div>
          </div>
        </div>
      </div>

    </div>
  </body>
</html>
